---
marp: true
---
# ニューラルネットワーク

---

## 概要

ニューラルネットワークは、機械学習の一種であり、生物の神経回路を模倣した計算モデルです。特に、パターン認識やデータ分析に強力なツールとして広く使用されています。

---
## 主な特徴

- **層構造**: ニューラルネットワークは、入力層、中間層、出力層の3つの層で構成されます。
- **活性化関数**: 各層のノード（ニューロン）は、活性化関数を通じて出力を生成します。一般的なものには、シグモイド関数やReLU（Rectified Linear Unit）があります。

$$
f(x) = \begin{cases} 
0 & \text{if } x < 0 \\ 
x & \text{if } x \geq 0 
\end{cases}
$$

---

## 応用分野

- 画像認識
- 自然言語処理
- 音声認識
- ロボティクス

---

## 研究グループ

**MACHINE PERCEPTION AND ROBOTICS GROUP**では、ニューラルネットワークを用いたさまざまな研究を行っています。特に、ロボットの知覚能力向上に向けた取り組みが注目されています。 

---

## 画像

<ニューラルネットワークの構造を示す図>

---

# ニューラルネットワークの構造

---

## 入力層 (input layer)
- ニューラルネットワークが特徴ベクトルを受け取る層であり、入力層に入力された特徴ベクトルを中間層に転送します。

## 中間層 (hidden layer)
- 各中間層はニューロンの集合であり、中間層のニューロンは前層の全てのニューロンと全結合されています。

## 出力層 (output layer)
- 最終の全結合層であり、出力層のニューロンは識別問題においてはクラススコアを表現します。

---

## ニューラルネットワークの全結合図
<ニューラルネットワークの全結合を示す図>

---

# 多層パーセプトロン (Multi-Layer Perceptron; MLP)

## 概要

- 入力を順に伝播して出力を計算します。

## 学習プロセス

- 出力と教師信号の誤差を各層に逆伝播できれば、結合重みを更新可能です。

## 逆誤差伝播法 (Back Propagation)


- 誤差が小さくなるように結合重みを調整します。
- このプロセスは勾配降下法を用いて行われます。

---

# 勾配降下法 (Gradient Descent Method)

## 出力と教師信号の誤差
- 出力と教師信号の誤差と現時点の結合重みにおける傾きから更新量を決定
- 誤差の算出
- 更新量の算出

---

## 二乗誤差
- 二乗誤差を $0$ に近づけるよう傾きを求めて更新量を決定

$$
E = \frac{1}{2} (y - t)^2
$$

- ここで、$E$ は誤差、$y$ は出力、$t$ は教師信号です。

---
## 誤差関数の微分
- 誤差関数を微分して更新量を決定

- 重み $w$ の更新

$$
\frac{\partial E}{\partial w} = (y - t) \cdot \frac{\partial y}{\partial w}
$$

- 出力 $y$ と教師信号との誤差を微分可能にする必要あり

$\partial$ (デルタ)とは、偏微分を表す記号。偏微分は多変数関数において1つの変数のみに関する微分を行い、それ以外の変数は定数として固定する計算です。



## シグモイド関数
- シグモイド関数に基づく出力の計算

$$
y = \frac{1}{1 + e^{-z}} \quad \text{(ここで } z = wx \text{)}
$$

- 更新量

- 更新量は勾配を用いて決定されます。

---

# シグモイド関数による単純パーセプトロン

## 概要
単純パーセプトロンは、入力データに基づいて出力を生成する最も基本的なニューラルネットワークモデルです。このモデルでは、シグモイド関数を用いて出力を非線形に変換します。

## シグモイド関数
シグモイド関数は、次のように定義されます：

$$
S(x) = \frac{1}{1 + e^{-x}}
$$

この関数は、入力 $x$ に対して $0$ から $1$ の範囲で出力を生成します。

---

## 誤差逆伝播法
誤差逆伝播法は、ネットワークの重みを更新するための効果的な手法です。以下のステップで行われます：

1. **順伝播**: 入力データをネットワークに入力し、出力を計算します。
2. **誤差計算**: 出力と実際のラベルとの誤差を計算します。
3. **逆伝播**: 誤差をネットワークの逆方向に伝播させて、各重みの勾配を計算します。
4. **重み更新**: 勾配に基づいて重みを更新します。

## まとめ
シグモイド関数と誤差逆伝播法を組み合わせることで、単純パーセプトロンは効率的に学習を行い、非線形なデータを扱うことが可能になります。

---

# シグモイド関数による単純パーセプトロン

- 単純パーセプトロンは、線形分離可能な問題を解決するための基本的なニューラルネットワークの構成要素です。
- シグモイド関数は、出力を0から1の範囲にマッピングし、確率的な解釈を可能にします。

## 勾配を求める

- 誤差逆伝播法は、ニューラルネットワークの訓練において重要なアルゴリズムです。
- 出力層の誤差を計算し、それを用いて各層の重みを更新します。

$$
\text{誤差} = y - \hat{y}
$$

- ここで、$y$は実際の出力、$\hat{y}$はモデルの出力です。

---

## シグモイド関数

- シグモイド関数は次のように定義されます。

$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$

- この関数の導関数は以下のように表されます。

$$
\sigma'(x) = \sigma(x)(1 - \sigma(x))
$$

- これにより、勾配降下法を通じて重みを更新することができます。

---

## 誤差逆伝播法の手順

1. **順伝播**: 入力データをネットワークに通し、出力を計算する。
2. **誤差計算**: 出力と実際のラベルの誤差を求める。
3. **逆伝播**: 誤差をネットワークに逆に伝搬させ、各重みの勾配を計算する。
4. **重み更新**: 学習率を用いて重みを更新する。

- このプロセスを繰り返すことで、モデルは訓練データに適合するようになります。

---

# 複数のパーセプトロンへの対応

## 誤差逆伝播法
複数のパーセプトロンを用いたニューラルネットワークにおいて、誤差逆伝播法は重要な役割を果たします。この手法では、出力層から入力層に向かって誤差を伝播させ、各層の重みを更新します。

---

### 数式の概念
パーセプトロンの出力は以下のように表されます：

$$
y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
$$

ここで、
- $y$ は出力
- $f$ は活性化関数
- $w_i$ は重み
- $x_i$ は入力
- $b$ はバイアス

---

逆誤差伝播法では、誤差 $\delta$ は次のように計算されます：


$$
\delta = (y - \hat{y}) f'(z)
$$

ここで、
- $\hat{y}$ は実際の出力
- $z$ はネット入力
- $f'$ は活性化関数の導関数

---

### 更新則
重みの更新は次の式で行われます：

$$
w_i^{new} = w_i^{old} - \eta \delta x_i
$$

ここで、$\eta$ は学習率です。

このように、逆誤差伝播法を用いることで、複数のパーセプトロンを効率的に学習させることが可能になります。

---



# 中間層を持つネットワークへの対応

---

## 誤差逆伝播法

### 多層パーセプトロン - 1出力

中間層を持つネットワークでは、複数の出力を得るために誤差逆伝播法を使用します。これは、誤差を出力層から入力層に向かって伝播させることで、各層の重みを更新する手法です。

### 重みの表記

重みは通常、次のように表記されます：

- $w_{ij}$: 入力層のノード$i$から中間層のノード$j$への重み

ここで、多層パーセプトロンの例を考えます。

---

### 例:

- 重み $w_{11}$, $w_{12}$ などの表記を用いて、各層の間の関係性を示します。

![重みの視覚的表現](<重みの視覚的表現を示す図>)

---

# 誤差逆伝播法：多層パーセプトロン-1出力(まとめ)

## 概要

誤差逆伝播法は、ニューラルネットワークの学習における重要なアルゴリズムです。この手法は、多層パーセプトロン（MLP）のような深層学習モデルで広く使用されています。

---

## 主なステップ

1. **フォワードパス**:
   - 入力データをネットワークに通し、出力を計算します。
   - 各層の出力は以下のように計算されます：
     $$ a^{(l)} = f(z^{(l)}) $$
     ここで、$ z^{(l)} = W^{(l)} a^{(l-1)} + b^{(l)} $ です。

---

2. **損失の計算**:
   - 出力層での損失関数を使用して誤差を評価します。
   - 例えば、二乗誤差の場合：
     $$ L = \frac{1}{2} (y - a^{(L)})^2 $$

---

3. **バックプロパゲーション**:
   - 出力層から入力層に向かって誤差を逆伝播させます。
   - 各層での誤差は以下で計算されます：
     $$ \delta^{(l)} = \nabla_a L \circ f'(z^{(l)}) $$

---

4. **重みの更新**:
   - 誤差を使用して重みとバイアスを更新します。
   - 更新式は次のようになります：
     $$ W^{(l)} \gets W^{(l)} - \eta \frac{\partial L}{\partial W^{(l)}} $$
     $$ b^{(l)} \gets b^{(l)} - \eta \frac{\partial L}{\partial b^{(l)}} $$

---

## まとめ

誤差逆伝播法は、深層学習におけるモデルの最適化に不可欠です。この手法により、モデルはデータから学習し、予測精度を向上させることができます。

---

# 誤差逆伝播法：更新式について

誤差逆伝播法（Backpropagation）は、ニューラルネットワークの学習において非常に重要なアルゴリズムです。この手法では、ネットワークの出力と実際の出力との誤差を計算し、その誤差をネットワークの各層に逆向きに伝播させて重みを更新します。

---

---

## 更新式

重みの更新は、以下の式によって行われます。

$$
w_{ij}^{(l)} \leftarrow w_{ij}^{(l)} - \eta \frac{\partial L}{\partial w_{ij}^{(l)}}
$$

ここで、  
- $w_{ij}^{(l)}$ は $l$ 層におけるニューロン $i$ からニューロン $j$ への重み
- $\eta$ は学習率
- $L$ は損失関数

---

## 誤差の計算

出力層の誤差 $\delta^{(L)}$ は以下のように計算されます。

$$
\delta^{(L)} = \nabla_a L \circ \sigma'(z^{(L)})
$$

ここで、  
- $\nabla_a L$ は出力層の損失に対する出力の勾配
- $\sigma'(z^{(L)})$ は活性化関数の導関数
- $\circ$ は要素ごとの積を表します。

---

## 隠れ層の誤差

隠れ層の誤差 $\delta^{(l)}$ は次のように計算されます。

$$
\delta^{(l)} = (\delta^{(l+1)} W^{(l+1)}) \circ \sigma'(z^{(l)})
$$

このようにして、各層の重みを順次更新していくことで、ネットワーク全体の誤差を減少させていきます。

---

## 偏微分によるデルタ

- デルタ( $\delta L$  )は、各ニューロンの出力に対する損失関数の偏微分を指します。

- このデルタ値は、ネットワーク内の各層での重み更新に必要な勾配を計算するために使われます。

- 具体的には、出力層から開始して、デルタを前の層へと伝播させることで、各重みに対する損失関数の勾配を効率的に計算します。

- これにより、勾配降下法を用いて重みを更新し、モデルの学習を進めることができます。

- 偏微分によるデルタの計算は、誤差をネットワーク全体で最小化するための重要なステップであり、深層学習モデルの訓練において不可欠な要素です。

---

# 多クラス分類

- 多クラス分類とは、与えられたデータを複数のクラスに分類する手法です。
- 分類結果は、softmax関数を用いて算出した確率が最大となるクラスが選ばれます。

# マルチラベル分類

- マルチラベル分類とは、与えられたデータが複数のラベル（クラス）に同時に属する可能性を予測する手法です。

## 予測方法

- 与えられたデータが各ラベル（クラス）ごとに属するか属さないかの有無を予測する2値分類として扱い、損失関数はバイナリクロスエントロピーを用います。

- 深層学習を使った方法では、出力層を複数のノードにして、各ラベルを予測するようにネットワークを設計します。

- 例えば、出力層が「眼鏡」、「ひげ」、「帽子」などのノードを持ち、各ノードが「そのラベルに該当するか」を予測します。

- 出力の確率の和が1にならないように活性化関数にsoftmax関数ではなく、sigmoid関数を用いて、各ラベル（クラス）に対して独立に確率を予測します。

- そのため各クラスの閾値を適切に決め、出力値が閾値を超えたクラスを付与します。

---

## softmax関数

$$
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}
$$

- ここで、$z_i$ はクラス $i$ に対する出力値です。
- softmax関数を適用することで、出力値が確率に変換されます。

---

## 多層パーセプトロンの出力

- 多層パーセプトロン（MLP）は、入力層、中間層、出力層から構成されています。
- 出力層の活性化関数としてsoftmaxを使用することで、各クラスに対する予測確率を得ることができます。

<多層パーセプトロンの構造を示す図>

---

# 回帰タスクと分類タスク

## 回帰タスク
- 実数値を予測するタスクです。
- 評価指標として二乗誤差 (L2 squared norm) が用いられます。

$$
L = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

ここで、$y_i$は実際の値、$\hat{y}_i$は予測値です。

---

# 平均絶対誤差

- 平均絶対誤差（Mean Absolute Error, MAE）は、回帰分析や予測モデルの性能を評価するための指標の一つで、予測値と実際の値との差（誤差）の絶対値の平均を示します。

- これにより、モデルの予測が実際の値とどれだけ近いかを表すことができ、予測の精度を定量的に示すことができます。

- 平均絶対誤差の計算方法：

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

- $y_i$ : 実際の値（観測値）

- $hat{y}_i$: 予測値

- $n$ : データのサンプル数

- $∣y_i - hat{y}_i∣$ : 各データにおける誤差の絶対値

---

## 特徴

- 平均絶対誤差は、実際の値と予測値との差の「平均的な大きさ」を示すので、誤差の絶対的な大きさがわかりやすく、非常に直感的です。

- 平均絶対誤差の単位は予測対象の値の単位と一致します。例えば、予測する値が金額であれば、平均絶対誤差の単位も金額になります。

- 平均絶対誤差は、外れ値（異常値）に対して比較的頑健です。

- 大きな誤差があったとしても、その影響は絶対値で取るため、誤差が非常に大きくても平均に対する影響は大きくならず、平均二乗誤差（MSE）よりも外れ値に敏感ではありません。

---

## 分類タスク
- クラスを予測するタスクです。
- 損失関数 (Loss function) としてクロスエントロピーが用いられます。

$$
L = -\sum_{i=1}^{n} y_i \log(\hat{y}_i)
$$

ここで、$y_i$は実際のクラスラベル、$\hat{y}_i$は予測確率です。

(追加)

2つのクラスに分類するタスクでは、バイナリクロスエントロピーが損失関数として使用できます。

$$
L = -y_i \log \hat{y}_i - (1 - y) \log(1 - \hat{y}_i)
$$

---

(追加)
# 順序回帰

- 順序回帰とは、順序が決まった複数の目的変数の中から1つのクラスを予測するタスクです。

- 2値分類として定式化する方法と多クラス分類として定式化する方法があります。

- 例：

- 嗜好品の5段階評価（とても悪い、悪い、普通、良い、とても良い）を予測する問題

- 年齢を10歳ごとに（0~9歳、10~19歳、20~29歳）のように区分しある人の年齢がどの区分に入るかを予測する問題

- 多クラス分類との違い

- 多クラス分類では正解クラスは1つだけであり、予測の評価は正解か誤りかの2種類しかありません。

- これに対して上記の例では「惜しい」誤答、つまり正解と順序が近い誤答が存在します。順序回帰では、そのような正解の近さを考慮します。

---

## 2値分類として解く方法

- クラス数Kとした時、タスクをK-1の独立な2値分類として定式化します。

- 具体的には、K個の順序付きクラスをインデックスk = 1, … , Kで表した時、それぞれのクラスについて入力xの正解クラスbar{k}がそれより大きいか、そうではないかを判定する2値分類を考えます。

- 最後のクラスKとの比較は意味がないのでk = 1, … , K - 1について2値分類を考えることになりますが、その正解dk(k = 1, … , K - 1)は

$$
d_k=1, \, k<{\bar k}のとき\\d_k=0,\,それ以外
$$

- これに合わせてネットワークの出力層にK - 1個のユニットを並べ、シグモイド関数を活性化関数として、その出力にykでdkを予測します。

- こうして得られる出力y1, … , yK-1を、しきい値を決めて2値化すると理想的には正解クラスbar{k}よりも小さいkの出力が全て”1”でそれ以外が全て”0”すなわち

$$
[y_1, ..., y_{K-1}] = _{\bar{k}-1}[1, ..., 1, 0, ..., 0]_{K-\bar{k}}
$$

- ただし各kの2値分類は独立に行っているので、予測が上のようになる保証はありません。

- そこでK - 1個の2値分類の結果を加算したものをxのクラスの予測とします。

$$
(予測するクラスのインデックス)=1+\sum_{k=1}^{K-1}1\{y_k\}
$$

- ここで$1{y_k}は${y_k}$を2値化する処理を表します。

---

## 多クラス分類として解く方法

- Kクラスの多クラス分類として定式化して、目標出力dにソフトラベルを使用します。

- 多クラス分類の目標出力は通常、1-of-K符号（ハードラベルとも呼ばれる）で与えますが、ここではクラスkのdkを正解との近さに応じて、0から1の間の値を取るようにします。

- これよって「惜しい」誤答を、正解への近さに応じてに適切に評価できるようになります。

- 具体的には、正解クラスbar{k}との距離|bar{k} - k|(k = 1, … , K)をソフトマックス関数で正規化したものを用います。

$$
d_k=\frac{\exp(-|{\bar k}-k|)}{\sum_{i=1}^K\exp(-|{\bar k}-i|)}
$$

- K個のユニット＋ソフトマックス関数を出力層に持つネットワークを使って、交差エントロピーを最小化する学習を行います。

- 推論時には、スコア${y_k}$が最大となるクラスkをこたえとします。

---

# 過学習 (Overfitting)

- 訓練データに対して学習されているが，未知データ（テストデータ）に対して適合できていない，汎化できていない状態を指す

## 原因
- パラメータを大量にもち，表現力が高いモデルであること（深いネットワーク）
- 訓練データが少ないこと

---

## ドロップコネクト

- ドロップコネクトは、ニューラルネットワークの重み（接続）をランダムに無効化する正則化手法です。

- これは過学習を防ぐために用いられ、各エポックで異なるサブネットワークを学習する効果があります。

- ドロップアウトがノードを無効化するのに対し、ドロップコネクトは個々の重みを無効化するため、より細かな正則化が可能です。

- これにより、モデルの汎化性能が向上し、未知のデータに対する予測精度が高まります。

<図: ドロップコネクトの図>

---

## 検証用データの誤差

<検証用データの誤差を示すグラフ>

---

# 確率的勾配降下法（ミニバッチ学習）

- 少量の学習サンプルを一度に用いて誤差を求め更新
- 結合重みの更新方法は以下の式で表されます：

$$
w \leftarrow w - \eta \nabla L(w)
$$

ここで、$w$ は結合重み、$\eta$ は学習率、$L(w)$ は損失関数、$\nabla L(w)$ は損失関数の勾配です。

---

# エポックとミニバッチ

## エポック数
- エポック数は、一つの訓練データ（全学習サンプル）を何回繰り返して学習するかを示す指標です。

## エポックとミニバッチ
- エポックは全データを使った学習の単位であり、ミニバッチはその中の一部のデータセットを指します。
- ミニバッチ学習は、全データを一度に使うのではなく、小さなデータセットで学習を行うことで計算効率を向上させます。

![学習プロセスの図](エポックとミニバッチの関係を示す図)

---

# エポック数とミニバッチのサイズを変更した際の学習の推移

## ミニバッチ学習

- エポック数を増加させると、学習の精度が向上する傾向にあります。
- ミニバッチのサイズを調整することで、学習の安定性や収束速度にも影響があります。

- 学習曲線を視覚化するためには、以下のようなグラフが必要です。
  - **グラフの説明**: エポック数に対する損失の推移を示すラインプロット。


---

# 最急降下法と勾配降下法

## 概要
- **最急降下法**（Gradient Descent）は、パラメータで損失関数を微分することで、損失を小さくする方向にパラメータを逐次更新する手法です。

## 手法
- パラメータ更新の一般式は以下のようになります：
$$
\theta_{t+1} = \theta_t - \alpha \nabla L(\theta_t)
$$
ここで、$\theta$はパラメータ、$\alpha$は学習率、$L(\theta)$は損失関数、$\nabla L(\theta_t)$は勾配です。

---

---

### 特徴
- 勾配に基づき、最適な解を見つけるための効率的な手法です。
- 学習率の設定が重要で、適切でない場合は収束が遅くなったり、発散することがあります。

## まとめ
最急降下法は、機械学習や最適化において重要な役割を果たす手法であり、実用的なアルゴリズムの基盤となっています。

---

# モーメンタム

- モーメンタムとは「運動量」という意味であり、パラメータ空間をボールが転がって極値にたどり着くように更新します。

---

## Pathological Curvature

- Pathological Curvature（病的な曲率）は、損失関数の曲面がある方向には急峻で、別の方向には緩やかな場合を指します。

- 深層学習では、このような不均一な曲率が最適化アルゴリズムの収束を妨げます。

- 具体的には、急峻な方向では大きな勾配が生じる一方、緩やかな方向では勾配が小さくなるため、学習率の調整が難しくなります。

- その結果、最適化が遅延したり、最悪の場合は収束しないことがあります。これにより、モデルの性能が低下し、学習プロセスが非効率になる問題が生じます。

- この対策として、モーメンタムが挙げられます。

<図:Pathological Curvatureの図>

---

## 最適化におけるモーメンタム

- モーメンタムを用いることで、最適化の収束を早めることができます。具体的には、過去の勾配を考慮して現在の更新を行うため、振動を減少させ、よりスムーズに極値に到達します。

- モーメンタムの更新式は以下のように表されます。

$$
v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta_t)
$$

$$
\theta_{t+1} = \theta_t - \alpha v_t
$$

ここで、$v_t$ はモーメンタムの値、$\beta$ はモーメンタム係数、$\alpha$ は学習率、$\nabla L(\theta_t)$ は損失関数の勾配です。

---

## Nesterov Accelerated Gradient

- Nesterov Accelerated Gradient（NAG）はモーメンタム法の改良版で、将来の位置での勾配を考慮します。

- まず、モーメンタムを用いて予測位置を計算し、その位置での勾配を評価します。

- その結果を元に実際の更新を行うことで、オーバーシュートを防ぎつつ、より高速な収束が期待できます。

- Nesterov Accelerated Gradientの更新式は以下のように表されます。

$$
\theta_{t+1} = \theta_t - \alpha (1 - \beta) \nabla L(\theta_t + \beta (\theta_t - \theta_{t-1})) + \beta (\theta_t - \theta_{t-1})
$$

---

# 最適化手法：AdaGrad

- 極値に近づくほど更新量が小さくなるように調整します。


- 更新量の調整により、各パラメータの学習率が適応的に変化し、特に稀な特徴に対しても効果的に学習を行うことができます。

$$
\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{G_t} + \epsilon} \nabla L(\theta_{t-1})
$$

ここで、
- $\theta_t$ は更新後のパラメータ
- $\eta$ は初期学習率
- $G_t$ は勾配の二乗和（過去の勾配の情報を蓄積）
- $\epsilon$ は数値安定性のための小さな定数


---

# RMSProp

## Adagradを改良した手法

- $\alpha$ により過去の勾配の影響を抑える
- 直近の勾配情報を優先して学習率を決める

最適化手法の一つとして、RMSPropが提案されました。これは、Adagradの欠点を克服するために設計されています。RMSPropは、勾配の二乗の移動平均を使用することで、学習率を調整します。これにより、学習の安定性が向上します。

---

## RMSPropの数式

RMSPropの更新式は以下のように表されます：

$$
v_t = \beta v_{t-1} + (1 - \beta) g_t^2
$$

$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{v_t} + \epsilon} g_t
$$

ここで、$v_t$ は勾配の二乗の移動平均、$g_t$ は現在の勾配、$\eta$ は学習率、$\epsilon$ は数値安定性のための小さな定数です。

---

# Adam最適化手法

- AdamはMomentumとAdaGradを融合した最適化手法です。

## Adamの特徴

- **適応的学習率**: 各パラメータに対して異なる学習率を持つ
- **Momentumの利用**: 過去の勾配を考慮し、更新を滑らかにする

---

## 数式

Adamの更新式は以下の通りです：

$$
\theta_t = \theta_{t-1} - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
$$

ここで、
- $\theta_t$: パラメータ
- $\alpha$: 学習率
- $\hat{m}_t$: 勾配のモーメンタム
- $\hat{v}_t$: 勾配の二乗の平均
- $\epsilon$: 非常に小さな数（ゼロ除算を防ぐため）

--- 

## Adamの利点

- 収束が速い
- スパースな勾配問題に強い

## 参考文献

- Diederik P. Kingma, Jimmy Ba, "Adam: A Method for Stochastic Optimization", arXiv:1412.6980, 2015.

---

# Optimizer（SGD, Momentum, AdaGrad, Adam）の比較

## 最適化手法の概要

- **SGD (Stochastic Gradient Descent)**: 
  - 勾配降下法の一種で、パラメータを更新する際にミニバッチを使用。
  - 更新式: 
  $$
  \theta = \theta - \eta \nabla L(\theta)
  $$

---

- **Momentum**: 
  - SGDに慣性の概念を導入し、過去の勾配を考慮して更新を行う。
  - 更新式:
  $$
  v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta)
  $$
  $$
  \theta = \theta - \eta v_t
  $$

---

- **AdaGrad**: 
  - 各パラメータに対して適応的に学習率を調整。
  - 更新式:
  $$
  \theta = \theta - \frac{\eta}{\sqrt{G_{t,i}} + \epsilon} \nabla L(\theta)
  $$
  ここで、$G_{t,i}$は過去の勾配の二乗和。

---

- **Adam (Adaptive Moment Estimation)**: 
  - MomentumとAdaGradの利点を組み合わせた手法。
  - 更新式:
  $$
  m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla L(\theta)
  $$
  $$
  v_t = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla L(\theta))^2
  $$
  $$
  \theta = \theta - \frac{\eta}{\sqrt{v_t} + \epsilon} m_t
  $$

---

## 各手法の特徴

- **SGD**: 単純で計算コストが低いが、収束が遅いことがある。
- **Momentum**: 局所的な最適解からの脱出を助け、収束を速める。
- **AdaGrad**: 学習率が自動的に調整されるが、学習が進むにつれて学習率が急激に減少する。
- **Adam**: 高速で安定した収束が期待でき、広く使用されている。

---

## まとめ

- 各手法にはそれぞれの利点と欠点があるため、問題の性質やデータセットに応じて適切な手法を選ぶことが重要。
- 実際の適用時には、ハイパーパラメータの調整も必要である。

<比較表やグラフの画像が必要>

---

# ドロップアウト

- ドロップアウト（Dropout）は、ニューラルネットワークの過学習を防ぐために使用される正則化手法です。

- 基本的なアイデアは、訓練中にランダムに一部のユニット（ノード）を「ドロップアウト」する、つまり、そのユニットの出力をゼロにしてしまうことです。

- この方法により、ネットワークは特定の特徴量に依存しすぎず、より一般化できるようになります。

<図:ドロップアウトの図>

## ドロップアウトの割合（ドロップアウト率、Dropout Rate）

- ドロップアウト率とは、ドロップアウトを適用するユニットの割合を示すハイパーパラメータです。

- 通常、0と1の間の値で指定します。

- ドロップアウト率 = 0: ドロップアウトは行われません。すべてのユニットが常にアクティブであり、過学習のリスクがあります。
- ドロップアウト率 = 1: すべてのユニットがゼロにされ、ネットワークが全く学習できなくなります。
- ドロップアウト率 = 0.5: 訓練時に50%のユニットがランダムに無効化され、残りのユニットが学習に使用されます。

## ドロップアウト率の選定

- ドロップアウト率はネットワークの構造やデータの性質に応じて調整が必要です。

- 通常、0.2から0.5の範囲で設定することが多いですが、最適な割合はハイパーパラメータ調整を通じて決定されます。

- 高すぎるドロップアウト率（例：0.7～0.9）: ネットワークが情報を十分に学習できなくなる可能性があり、性能が低下します。
- 低すぎるドロップアウト率（例：0～0.1）: 正則化の効果が薄れ、過学習のリスクが高くなる可能性があります。

---

# 正則化

- 正則化（regularization）は、モデルの過学習（オーバーフィッティング）を防ぐために、モデルにペナルティを加える手法です。

- 正則化は、モデルの複雑さを制限するために、損失関数に追加の項（正則化項）を加えることで行われます。

- これにより、モデルがあまりにも自由にデータに適合しすぎることを防ぎます。

## 正則化項

- 正則化項には主に以下の2つが使われます。

1. L2正則化（リッジ回帰）
- L2正則化は、モデルの重み（パラメータ）に対してペナルティを加える手法です。
- 損失関数に以下のような項が加わります
    
$$
損失関数=元の損失関数+\lambda \sum_{i} w_i^2
$$
    
- ここで、${w_i}$ はモデルの重み、$\lambda$ は正則化項の係数（ハイパーパラメータ）です。
- L2正則化では、重みが大きくなることを防ぐことで、モデルの複雑さを抑えます。
    
2. L1正則化（ラッソ回帰）
- L1正則化も同様に重みにペナルティを加えますが、そのペナルティは重みの絶対値の和です。
- 損失関数は次のようになります
    
$$
損失関数=元の損失関数+\lambda \sum_{i} |w_i|
$$
    
- L1正則化の特徴は、重みがゼロになることがある点です。
- これにより、特徴量選択の効果があり、重要でない特徴量を自動的に除外します。
    
## 正則化項の係数（λ）

- 正則化項の係数$\lambda$は、正則化の強さを制御します。

- 具体的には、以下のように動作します

- λ=0: 正則化がない状態で、モデルは訓練データに対して最適化されます（過学習しやすくなります）。
- λ>0: 正則化が適用され、モデルはより単純に、過学習を防ぐように働きます。正則化の強さが増すほど、モデルは訓練データに適合しすぎなくなり、汎化能力が向上します。
- λが大きすぎる: モデルの重みが極端に小さくなりすぎ、過度に単純なモデルになる場合があります。この場合、アンダーフィッティング（過少適合）が発生し、モデルがデータに適切にフィットしないことがあります。

---

# ベイズ最適化

- ベイズ最適化（Bayesian Optimization）は、関数の最適化を行うための確率的手法の一つです。

- 特に、計算コストが高い、または評価が困難な目的関数に対して非常に効果的です。

- この方法は、特にハイパーパラメータのチューニングにおいて広く使われています。

## ベイズ最適化の基本的な考え方

- ベイズ最適化は、最適化したい関数がどのような形をしているかが明確でない、あるいは計算に多くの時間やコストがかかる場合に有効です。

- ベイズ最適化の主な特徴は、次の2つです。

1. 確率的モデル
- ベイズ最適化では、目的関数（例えば、機械学習モデルの性能など）を確率モデル（通常はガウス過程）で近似します。
- この確率モデルを使って、目的関数の予測とその不確実性を表現します。

2. 次に評価する点の選定
- ベイズ最適化では、次にどのパラメータを評価するべきかを決めるために「獲得関数（Acquisition Function）」を使用します。
- この獲得関数は、現在の予測をもとに最も有望な点を決定します。

## ベイズ最適化の流れ

- ベイズ最適化は、以下のようなステップで進行します

1. モデルの初期化
- 初期のサンプル点（例えば、ランダムなハイパーパラメータの組み合わせ）を評価し、その結果を用いて確率モデル（通常、ガウス過程）を学習します。

2. 獲得関数の最適化
- 次にどの点（ハイパーパラメータの組み合わせ）を評価するかを決定します。
- 獲得関数は、探索（exploration）と活用（exploitation）をバランスよく取り、予測される性能が最も改善されるポイントを選びます。

3. 新しい評価の実行
- 獲得関数に基づいて選ばれた新しいハイパーパラメータで目的関数を評価します。
- この評価結果を確率モデルに追加し、モデルを更新します。

4. 繰り返し
- 上記のプロセスを繰り返し、最適なパラメータを見つけるまで続けます。

<図:目的関数の予測分布と獲得関数の図>

## 目的関数の予測分布と獲得関数の関係

- ベイズ最適化では、確率的モデルを用いて目的関数の予測分布を得ます。

- この予測分布は、特定の点での目的関数の出力を確率的に予測し、その不確実性も考慮します。

- 獲得関数は、この予測分布に基づいて次に評価すべき点を決定します。

- 例えば、ガウス過程を用いる場合、予測分布は目的関数の出力の平均と分散で表されます。

- この予測分布を利用して、獲得関数（例えば、期待改善（Expected Improvement））は、最も改善の見込みが高い点を選びます。

- この選定プロセスは、探索と活用のバランスを取ることが重要です。

## 獲得関数（Acquisition Function）

- 獲得関数は、次に評価する点を選ぶための基準です。

- 獲得関数にはいくつかの種類がありますが、代表的なものとして以下があります。

- 確率的改善（Probability of Improvement, PI）: 現在の最良結果より良い結果を得る確率が最大になるような点を選びます。
- 期待改善（Expected Improvement, EI）: 現在の最良結果に対する改善が期待できる点を選びます。この方法は、予測される改善量を最大化することを目指します。
- 上限信頼境界（Upper Confidence Bound, UCB）: 現在の予測値に対する不確実性を加味して、探索と活用のバランスを取る点を選びます。

## ベイズ最適化の利点

- 評価回数が限られている場合でも、高い精度で最適解に近づけるため、無駄な計算を避けることができます。

- 他の最適化手法が高次元空間で性能が悪くなるのに対して、ベイズ最適化は高次元問題にも対応できます。

---

# ニューラルネットワークの設計

## 人があらかじめ決めること
- ネットワークの構造
  - 層の数と各層の種類（畳み込み層，全結合層など）
  - 各層のカーネルサイズ，カーネル数，ユニット数

---

## 万能近似定理
- 隠れ層に十分なユニットがあれば，連続関数は3層ニューラルネットワークで近似可能（学習できるか不明）

---

## ネットワークの設計指針
- 深い構造の方が高い精度を達成
- ユニット数などの削減も可能
- 具体的な構造は，実験的に試行錯誤しながら模索

## アーキテクチャの設計
- ネットワークの選定
- ハイパーパラメータの調整
- 適切な評価指標の選択

<ネットワークアーキテクチャの例を示す図>

---

## 学習率の調整

- 深層学習における学習率の調整は、モデルの最適化において非常に重要です。
 
- 学習率は、勾配降下法でパラメータを更新する際の一歩の大きさを決定します。

- 学習率が高すぎると、最適解を飛び越えてしまい、損失が発散する可能性があります。

- 一方、学習率が低すぎると、学習が遅くなり、局所最適解に陥るリスクが高まります。そのため、適切な学習率を選択することが重要です。

<図:学習率の大小が学習の収束性に与える影響を説明した損失関数の断面図の図>

- 学習率の調整方法としては、一定のエポックごとに学習率を減少させる学習率減衰や、勾配の変化に応じて学習率を自動的に調整する適応的学習率アルゴリズム（例：Adam、RMSprop）などがあります。

- これらの手法を用いることで、モデルの収束を安定化させ、最適な性能を引き出すことができます。

---

# 計算をグラフで表現すると

## アーキテクチャの設計

- グラフは計算の関係性を視覚化する強力なツールです。
- ノード（点）はデータや変数を表し、エッジ（辺）はそれらの関係や操作を示します。

### グラフの利点
- 複雑な計算を簡潔に表現
- データの流れを直感的に理解
- アルゴリズムの最適化の手助け

---

### 例: ニューラルネットワーク
- ニューラルネットワークは、ノードがニューロンを、エッジがシナプスを表します。
- 入力から出力へのデータの流れをグラフで視覚化することで、モデルの動作を理解しやすくなります。

<ニューラルネットワークの構造を示す画像>
